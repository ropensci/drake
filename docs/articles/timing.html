<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Time: logging, prediction, and strategy • drake</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><meta property="og:title" content="Time: logging, prediction, and strategy">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">drake</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">5.1.3.9001</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/drake.html">Get Started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../articles/faq.html">FAQ</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/example-packages.html">Example: R package download trends</a>
    </li>
    <li>
      <a href="../articles/example-gsp.html">Example: gross state products</a>
    </li>
    <li>
      <a href="../articles/example-mtcars.html">Example: mtcars and workflow plan generation</a>
    </li>
    <li>
      <a href="../articles/best-practices.html">General best practices for drake projects</a>
    </li>
    <li>
      <a href="../articles/debug.html">Debugging and testing drake projects</a>
    </li>
    <li>
      <a href="../articles/graph.html">Graphs with drake</a>
    </li>
    <li>
      <a href="../articles/parallelism.html">Parallel computing</a>
    </li>
    <li>
      <a href="../articles/timing.html">Timing: logging, prediction, and strategy</a>
    </li>
    <li>
      <a href="../articles/storage.html">Storage</a>
    </li>
    <li>
      <a href="../articles/caution.html">Caution</a>
    </li>
    <li>
      <a href="../articles/faq.html">Frequently-asked questions</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">News</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/ropensci/drake">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Time: logging, prediction, and strategy</h1>
                        <h4 class="author">Will Landau</h4>
            
            <h4 class="date">2018-05-08</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/ropensci/drake/blob/master/vignettes/timing.Rmd"><code>vignettes/timing.Rmd</code></a></small>
      <div class="hidden name"><code>timing.Rmd</code></div>

    </div>

    
    
<p>Thanks to <a href="https://github.com/dapperjapper">Jasper Clarkberg</a>, <code>drake</code> records how long it takes to build each target. For large projects that take hours or days to run, this feature becomes important for planning and execution.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(drake)
<span class="kw"><a href="../reference/load_mtcars_example.html">load_mtcars_example</a></span>() <span class="co"># Get the code with drake_example("mtcars").</span>
<span class="kw"><a href="../reference/make.html">make</a></span>(my_plan, <span class="dt">jobs =</span> <span class="dv">2</span>)

<span class="kw"><a href="../reference/build_times.html">build_times</a></span>(<span class="dt">digits =</span> <span class="dv">8</span>) <span class="co"># From the cache.</span>
## # A tibble: 28 x 5
##    item                   type   elapsed        user           system     
##  * &lt;chr&gt;                  &lt;chr&gt;  &lt;S4: Duration&gt; &lt;S4: Duration&gt; &lt;S4: Durat&gt;
##  1 coef_regression1_large target 0.007s         0.002s         0.005s     
##  2 coef_regression1_small target 0.011s         0.01s          0s         
##  3 coef_regression2_large target 0.008s         0.008s         0.001s     
##  4 coef_regression2_small target 0.007s         0.007s         0.001s     
##  5 data.frame             import 0.035s         0.032s         0.003s     
##  6 knit                   import 0.034s         0.024s         0.005s     
##  7 large                  target 0.041s         0.022s         0.017s     
##  8 lm                     import 0.024s         0.016s         0.004s     
##  9 mtcars                 import 0.005s         0.002s         0.001s     
## 10 nrow                   import 0.008s         0.007s         0s         
## # ... with 18 more rows

<span class="co"># `dplyr`-style `tidyselect` commands</span>
<span class="kw"><a href="../reference/build_times.html">build_times</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/tidyselect/topics/select_helpers">starts_with</a></span>(<span class="st">"coef"</span>), <span class="dt">digits =</span> <span class="dv">8</span>)
## # A tibble: 4 x 5
##   item                   type   elapsed        user           system      
## * &lt;chr&gt;                  &lt;chr&gt;  &lt;S4: Duration&gt; &lt;S4: Duration&gt; &lt;S4: Durati&gt;
## 1 coef_regression1_large target 0.007s         0.002s         0.005s      
## 2 coef_regression1_small target 0.011s         0.01s          0s          
## 3 coef_regression2_large target 0.008s         0.008s         0.001s      
## 4 coef_regression2_small target 0.007s         0.007s         0.001s

<span class="kw"><a href="../reference/build_times.html">build_times</a></span>(<span class="dt">digits =</span> <span class="dv">8</span>, <span class="dt">targets_only =</span> <span class="ot">TRUE</span>)
## # A tibble: 15 x 5
##    item                   type   elapsed        user           system     
##  * &lt;chr&gt;                  &lt;chr&gt;  &lt;S4: Duration&gt; &lt;S4: Duration&gt; &lt;S4: Durat&gt;
##  1 coef_regression1_large target 0.007s         0.002s         0.005s     
##  2 coef_regression1_small target 0.011s         0.01s          0s         
##  3 coef_regression2_large target 0.008s         0.008s         0.001s     
##  4 coef_regression2_small target 0.007s         0.007s         0.001s     
##  5 large                  target 0.041s         0.022s         0.017s     
##  6 regression1_large      target 0.013s         0.012s         0s         
##  7 regression1_small      target 0.007s         0.007s         0s         
##  8 regression2_large      target 0.025s         0.01s          0.009s     
##  9 regression2_small      target 0.01s          0.01s          0s         
## 10 "\"report.md\""        target 0.071s         0.053s         0.016s     
## 11 small                  target 0.022s         0.02s          0.002s     
## 12 summ_regression1_large target 0.007s         0.007s         0s         
## 13 summ_regression1_small target 0.008s         0.007s         0.001s     
## 14 summ_regression2_large target 0.011s         0.009s         0s         
## 15 summ_regression2_small target 0.009s         0.009s         0.001s</code></pre></div>
<p>For <code>drake</code> version 4.1.0 and earlier, <code><a href="../reference/build_times.html">build_times()</a></code> just measures the elapsed runtime of each command in <code>my_plan$command</code>. For later versions, the build times also account for all the internal operations in <code>drake:::build()</code>, such as <a href="https://github.com/ropensci/drake/blob/master/vignettes/storage.Rmd">storage and hashing</a>.</p>
<div id="predict-total-runtime" class="section level1">
<h1 class="hasAnchor">
<a href="#predict-total-runtime" class="anchor"></a>Predict total runtime</h1>
<p>Drake uses these times to predict the runtime of the next <code><a href="../reference/make.html">make()</a></code>. At this moment, everything is up to date in the current example, so the next <code><a href="../reference/make.html">make()</a></code> should be fast. Here, we only factor in the times of the formal targets in the workflow plan, excluding any imports.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">config &lt;-<span class="st"> </span><span class="kw"><a href="../reference/drake_config.html">drake_config</a></span>(my_plan, <span class="dt">verbose =</span> <span class="ot">FALSE</span>)
<span class="kw"><a href="../reference/predict_runtime.html">predict_runtime</a></span>(config, <span class="dt">targets_only =</span> <span class="ot">TRUE</span>)
## [1] "0.257s"</code></pre></div>
<p>Suppose we change a dependency to make some targets out of date. Now, even though, the next <code><a href="../reference/make.html">make()</a></code> should take a little longer.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">reg2 &lt;-<span class="st"> </span><span class="cf">function</span>(d){
  d<span class="op">$</span>x3 &lt;-<span class="st"> </span>d<span class="op">$</span>x <span class="op">^</span><span class="st"> </span><span class="dv">3</span>
  <span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x3, <span class="dt">data =</span> d)
}

<span class="kw"><a href="../reference/predict_runtime.html">predict_runtime</a></span>(config, <span class="dt">targets_only =</span> <span class="ot">TRUE</span>)
## [1] "0.257s"</code></pre></div>
<p>But what if you plan on starting from scratch next time, either after <code><a href="../reference/clean.html">clean()</a></code> or with <code><a href="../reference/make.html">make(..., trigger = "always")</a></code>?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/predict_runtime.html">predict_runtime</a></span>(config, <span class="dt">from_scratch =</span> <span class="ot">TRUE</span>, <span class="dt">targets_only =</span> <span class="ot">TRUE</span>)
## [1] "0.257s"</code></pre></div>
</div>
<div id="strategize-your-high-performance-computing" class="section level1">
<h1 class="hasAnchor">
<a href="#strategize-your-high-performance-computing" class="anchor"></a>Strategize your high-performance computing</h1>
<p>Let’s say you are scaling up your workflow. You just put bigger data and heavier computation in your custom code, and the next time you run <code><a href="../reference/make.html">make()</a></code>, your targets will take much longer to build. In fact, you estimate that every target except for your R Markdown report will take two hours to complete. Let’s write down these known times in seconds.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">known_times &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">5</span>, <span class="kw">rep</span>(<span class="dv">7200</span>, <span class="kw">nrow</span>(my_plan) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))
<span class="kw">names</span>(known_times) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw"><a href="../reference/file_store.html">file_store</a></span>(<span class="st">"report.md"</span>), my_plan<span class="op">$</span>target[<span class="op">-</span><span class="dv">1</span>])
known_times
##            "report.md"                  small                  large 
##                      5                   7200                   7200 
##      regression1_small      regression1_large      regression2_small 
##                   7200                   7200                   7200 
##      regression2_large summ_regression1_small summ_regression1_large 
##                   7200                   7200                   7200 
## summ_regression2_small summ_regression2_large coef_regression1_small 
##                   7200                   7200                   7200 
## coef_regression1_large coef_regression2_small coef_regression2_large 
##                   7200                   7200                   7200</code></pre></div>
<p>How many parallel jobs should you use in the next <code><a href="../reference/make.html">make()</a></code>? The <code><a href="../reference/predict_runtime.html">predict_runtime()</a></code> function can help you decide. <code><a href="../reference/predict_runtime.html">predict_runtime(jobs = n)</a></code> simulates how the targets are be distributed among <code>n</code> workers and then reports the virtual runtime of the busiest worker.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">time &lt;-<span class="st"> </span><span class="kw">c</span>()
<span class="cf">for</span> (jobs <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">12</span>){
  time[jobs] &lt;-<span class="st"> </span><span class="kw"><a href="../reference/predict_runtime.html">predict_runtime</a></span>(
    config,
    <span class="dt">jobs =</span> jobs,
    <span class="dt">from_scratch =</span> <span class="ot">TRUE</span>,
    <span class="dt">known_times =</span> known_times
  )
}
<span class="kw">library</span>(ggplot2)
<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggplot">ggplot</a></span>(<span class="kw">data.frame</span>(<span class="dt">time =</span> time <span class="op">/</span><span class="st"> </span><span class="dv">3600</span>, <span class="dt">jobs =</span> <span class="kw">ordered</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">12</span>), <span class="dt">group =</span> <span class="dv">1</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/geom_path">geom_line</a></span>(<span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/aes">aes</a></span>(<span class="dt">x =</span> jobs, <span class="dt">y =</span> time, <span class="dt">group =</span> group)) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/scale_continuous">scale_y_continuous</a></span>(<span class="dt">breaks =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">10</span> <span class="op">*</span><span class="st"> </span><span class="dv">4</span>, <span class="dt">limits =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">29</span>)) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/ggtheme">theme_gray</a></span>(<span class="dv">12</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">xlab</a></span>(<span class="st">"`jobs` argument to make()"</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw"><a href="http://www.rdocumentation.org/packages/ggplot2/topics/labs">ylab</a></span>(<span class="st">"Predicted runtime of make() (hours)"</span>)</code></pre></div>
<p><img src="timing_files/figure-html/predictjobs-1.png" width="700"></p>
<p>Now, let’s say your laptop has 4 single-threaded cores, so you cannot realistically see major performance improvements beyond 4 jobs. Theoretically, if your assumptions about <code>known_times</code> are correct, you should still be able to finish in about 8 hours.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/make.html">make</a></span>(my_plan, <span class="dt">jobs =</span> <span class="dv">4</span>)</code></pre></div>
<p>But you can chop the time in half if you set <code>jobs</code> to 7 and send your targets to a computing cluster. See the <a href="https://ropensci.github.io/drake/articles/parallelism.html">parallelism computing guide</a> for more on how this works.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Log into the cluster's head node / login node and start R.</span>
<span class="op">$</span><span class="st"> </span>ssh you<span class="op">@</span>login_node.your_cluster.com
<span class="co"># Deployment to the cluster happens through future and future.batchtools.</span>
<span class="kw">library</span>(future.batchtools)
<span class="co"># Write batchtools.slurm.tmpl that tells future.batchtools</span>
<span class="co"># how to talk to the compute nodes on the cluster.</span>
<span class="co"># You should modify and tailor it to your specific computing resource needs.</span>
<span class="co"># For example, make sure your wall time limit is over 2 hours.</span>
<span class="kw"><a href="../reference/drake_batchtools_tmpl_file.html">drake_batchtools_tmpl_file</a></span>(<span class="st">"slurm"</span>)
<span class="co"># Connect future to the cluster.</span>
future<span class="op">::</span><span class="kw"><a href="http://www.rdocumentation.org/packages/future/topics/plan">plan</a></span>(batchtools_slurm, <span class="dt">template =</span> <span class="st">"batchtools.slurm.tmpl"</span>)
<span class="co"># Each target goes to its own node on the cluster,</span>
<span class="co"># with up to 7 targets running at a time.</span>
<span class="kw"><a href="../reference/make.html">make</a></span>(my_plan, <span class="dt">parallelism =</span> <span class="st">"future"</span>, <span class="dt">jobs =</span> <span class="dv">7</span>, <span class="dt">verbose =</span> <span class="dv">4</span>)</code></pre></div>
<p>But why 7 jobs? Why not 8? 8 seems more intuitive when you look at the dependency graph and see a column of 8 targets.</p>
<iframe src="https://ropensci.github.io/drake/images/outdated.html" width="100%" height="600px" allowtransparency="true" style="border: none; box-shadow: none">
</iframe>
<p>The key is to think in terms of load balancing for persistent workers (transient workers should be similar here). Each free worker moves to each next free target as soon as possible, minimizing idle time. This splits the 14 computationally expensive targets evenly over the 7 workers. If you add another worker, you will still have workers with two expensive targets, each of which will run for 4 hours.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">balance &lt;-<span class="st"> </span><span class="kw"><a href="../reference/predict_load_balancing.html">predict_load_balancing</a></span>(
  config,
  <span class="dt">jobs =</span> <span class="dv">7</span>,
  <span class="dt">from_scratch =</span> <span class="ot">TRUE</span>,
  <span class="dt">targets_only =</span> <span class="ot">TRUE</span>,
  <span class="dt">known_times =</span> known_times
)
balance
## # A tibble: 7 x 3
##   worker targets   time             
##    &lt;int&gt; &lt;list&gt;    &lt;S4: Duration&gt;   
## 1      1 &lt;chr [3]&gt; 14405s (~4 hours)
## 2      2 &lt;chr [2]&gt; 14400s (~4 hours)
## 3      3 &lt;chr [2]&gt; 14400s (~4 hours)
## 4      4 &lt;chr [2]&gt; 14400s (~4 hours)
## 5      5 &lt;chr [2]&gt; 14400s (~4 hours)
## 6      6 &lt;chr [2]&gt; 14400s (~4 hours)
## 7      7 &lt;chr [2]&gt; 14400s (~4 hours)
<span class="kw">max</span>(balance<span class="op">$</span>time) <span class="op">/</span><span class="st"> </span><span class="dv">3600</span>
## [1] 4.001389
balance<span class="op">$</span>targets
## [[1]]
## [1] "large"                  "coef_regression1_large"
## [3] "\"report.md\""         
## 
## [[2]]
## [1] "small"                  "summ_regression2_large"
## 
## [[3]]
## [1] "regression1_large"      "coef_regression2_large"
## 
## [[4]]
## [1] "regression2_large"      "summ_regression1_small"
## 
## [[5]]
## [1] "regression1_small"      "coef_regression1_small"
## 
## [[6]]
## [1] "regression2_small"      "coef_regression2_small"
## 
## [[7]]
## [1] "summ_regression1_large" "summ_regression2_small"</code></pre></div>
<p>But be warned: if you use the staged parallel backends <code><a href="../reference/make.html">make(parallelism = "mclapply_staged")</a></code> or <code><a href="../reference/make.html">make(parallelism = "parLapply_staged")</a></code>, the maximum number of useful jobs really will be 8. Here, if all targets are out of date, the dependency graph is divided into conditionally independent columns and parallelism is only applied in within each column. If some targets are already up to date, those targets are skipped, and each stage is packed with as many outdated targets as possible. Either way, each stage needs to wait for the last target to finish. So if you have computationally expensive targets, this approach is not recommended. However, staged parallelism remains a fast, low-overhead option for workflows with a large number of small, conditionally independent targets.</p>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#predict-total-runtime">Predict total runtime</a></li>
      <li><a href="#strategize-your-high-performance-computing">Strategize your high-performance computing</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by William Michael Landau.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
