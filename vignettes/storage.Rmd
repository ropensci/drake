---
title: "Storage"
subtitle: "Caching, hashing, and customization"
author: "William Michael Landau"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    number_sections: true
vignette: >
  %\VignetteIndexEntry{storage}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

![](logo-vignettes.png)

```{r suppression, echo = F}
suppressMessages(suppressWarnings(library(drake)))
clean(destroy = TRUE)
unlink(
  c(
    "Makefile", "report.Rmd", "shell.sh",
    "STDIN.o*", "Thumbs.db",
    "faster_cache", "my_storr"
  ),
  recursive = TRUE
)
```

# Storage basics

When you run `make()`, `drake` puts your imports and output targets in a hidden cache, or storage location.


```{r basic_storage}
library(drake)
load_basic_example()
config <- make(my_plan, verbose = FALSE, return_config = TRUE)
```

You can explore your cached data using functions like `loadd()`, `readd()`, and `cached()`.

```{r explore_basic}
head(cached())
readd(small)
loadd(large)
head(large)
rm(large) # Does not remove `large` from the cache.
```

# Caches as R objects

The [storr](https://github.com/richfitz/storr) package does the heavy lifting. A `storr` is an object in R that serves as an abstraction for a storage backend, usually a file system. See the [main storr vignette](https://cran.r-project.org/package=storr/vignettes/storr.html) for a thorough walkthrough.

```{r get_storrs}
class(config$cache) # from `config <- make(..., return_config = TRUE)`
cache <- get_cache() # Get the default cache from the last build.
class(cache)
cache$list() # functionality from storr
cache$get("small") # functionality from storr
```

# Hash algorithms

The key to [storr](https://github.com/richfitz/storr)'s internals is the concept of  [hashing](https://en.wikipedia.org/wiki/Hash_function). [Storr](https://github.com/richfitz/storr) uses hashes to label what they store, and `drake` leverages these hashes to figure out what is up to date and what needs to be (re)built. A hash is like a fingerprint for a piece of data, so the hash should change if the dataset changes. Regardless of the data's size, the hash always has same number of characters.

```{r hashes}
library(digest) # package for hashing objects and files
smaller_data <- 12
larger_data <- rnorm(1000)
digest(smaller_data) # compute the hash
digest(larger_data)
```

However, different hash algorithms vary in output length.

```{r compare_algo_lengths}
digest(larger_data, algo = "sha512")
digest(larger_data, algo = "md5")
digest(larger_data, algo = "xxhash64")
digest(larger_data, algo = "murmur32")
```

# Which hash algorithm should you choose?

Hashing is expensive, and unsurprisingly, shorter hashes are usually faster to compute. So why not always use `murmur32`? One reason is the risk of collisions: when two different objects have the same hash. In general, shorter hashes have higher risks of collisions. We want our fingerprints to be unique. On the other hand, a longer hash is not always the answer. Besides speed, the decision depends on how we use the output. `Drake` and [storr](https://github.com/richfitz/storr) both use hash keys as names for internal cache files, and in general, file names should respect the 260-character cap on Windows file paths. That is why `drake` uses a shorter hash algorithm for internal cache-related file names and a longer hash algorithm for everything else.

```{r justified_hash_choices}
default_short_hash_algo() # for drake
default_long_hash_algo()
short_hash(cache)
long_hash(cache)
```

# Select the hash algorithms of the default cache

For new projects, use `new_cache()` to set the hashes of the default cache.

```{r default_cache_reset}
cache_path(cache) # default cache from before
clean(destroy = TRUE) # start from scratch to reset both hash algorithms
tmp <- new_cache(
  path = default_cache_path(), # the `.drake/` folder
  short_hash_algo = "crc32",
  long_hash_algo = "sha1"
)
```

The cache at `default_cache_path()` (equivalently, the `.drake/` folder) is the default cache used for `make()`.

```{r default_cache_control}
config <- make(my_plan, verbose = FALSE, return_config = TRUE)
short_hash(config$cache) # would have been xxhash64 (default_short_hash_algo())
long_hash(config$cache) # would have been sha256 (default_long_hash_algo())
```

You can change the long hash algorithm without throwing away the cache, but the project will rebuild from scratch. As for the short hash, you are committed until you delete the cache and its supporting files.

```{r more_cache}
outdated(my_plan, verbose = FALSE) # empty
config$cache <- configure_cache(
  config$cache,
  long_hash_algo = "murmur32",
  overwrite_hash_algos = TRUE
)
```

Below, the targets become outdated because the existing hash keys do not match the new hash algorithm.

```{r newhashmorecache}
outdated(my_plan, verbose = FALSE)
config <- make(my_plan, verbose = FALSE, return_config = TRUE)
short_hash(config$cache) # same as before
long_hash(config$cache) # different from before
```


# More on custom caches

You do not need to use the default cache whose files are at `default_cache_path()` (`.drake/`). However, if you use a different file system, such as the custom `faster_cache/` folder below, you will need to manually supply the cache to all functions that require one.

```{r, custom cache}
faster_cache <- new_cache(
  path = "faster_cache",
  short_hash_algo = "murmur32",
  long_hash_algo = "murmur32"
)
cache_path(faster_cache)
cache_path(cache) # location of the previous cache
short_hash(faster_cache)
long_hash(faster_cache)
new_plan <- workflow(
  simple = 1 + 1
)
make(new_plan, cache = faster_cache)
cached(cache = faster_cache)
readd(simple, cache = faster_cache)
```

# Recovering the cache

You can recover an old cache from the file system. You could use `storr::storr_rds()` directly if you know the short hash algorithm, but `this_cache()` and `recover_cache()` are safer for `drake`.

```{r oldcachenoeval, eval = FALSE}
old_cache <- this_cache("faste_cache") # Get a cache you know exists...
recovered <- recover_cache("faster_cache") # or create a new one if missing.
```

# More on [storr](https://github.com/richfitz/storr) caches

If you want bypass `drake` and generate a cache directly from [storr](https://github.com/richfitz/storr), it is best to do so right from the beginning.

```{r use_storr_directly}
library(storr)
my_storr <- storr_rds("my_storr", mangle_key = TRUE)
make(new_plan, cache = faster_cache)
cached(cache = faster_cache)
readd(simple, cache = faster_cache)
```

`Drake` supports [storr_rds()](https://github.com/richfitz/storr) caches. Other caches may be possible, but they should have a `storr`-like API and [namespace support](https://github.com/richfitz/storr/blob/master/vignettes/storr.Rmd#namespaces).

# In-memory caches

Some caches store your data in the computer's memory rather than saved files. `Drake` can make use of these in-memory caches, but not with any kind of parallel computing. In other words, when you call `make()`, the `parallelism` argument cannot be `"Makefile"` and `jobs` must be `1` (default). Also, keep in mind that unless you save your workspace, your in-memory cache will disappear when you close your R session.

```{r memory_caches}
memory_cache <- storr_environment()
other_plan <- workflow(
  some_data = rnorm(50),
  more_data = rpois(75, lambda = 10),
  result = mean(c(some_data, more_data))
)
make(other_plan, cache = memory_cache)
cached(cache = memory_cache)
readd(result, cache = memory_cache)
```

# Cache types

`Drake` has functions to help you create caches with known supported types.

```{r cache_types}
default_cache_type()
cache_types()
in_memory_cache_types()
env <- new.env()
my_type <- new_cache(type = "storr_environment")
my_type_2 <- new_cache(type = "storr_environment", envir = env)
ls(env)
```

For new in-memory caches, please use `new_cache()` rather than `get_cache()` or `recover_cache()`.

# Cleaning up

If you want to start from scratch, you can `clean()` the cache. Use the `destroy` argument to remove it completely. `cache$del()` and `cache$destroy()` are also options, but they leave output file targets dangling. By contrast, `clean(destroy = TRUE)` removes file targets generated by `drake::make()`.

```{r cleaning_up}
clean(small, large)
cached() # 'small' and 'large' are gone
clean(destroy = TRUE)
clean(destroy = TRUE, cache = faster_cache)
clean(destroy = TRUE, cache = my_storr)
```

```{r cleanup_storage, echo = FALSE}
unlink(c("Makefile", "report.Rmd", "shell.sh", "STDIN.o*", "Thumbs.db"))
```
