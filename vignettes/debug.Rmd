---
title: "Debugging and testing drake projects"
author: "William Michael Landau"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    number_sections: true
vignette: >
  %\VignetteIndexEntry{debug}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r debugstart, echo = F}
suppressMessages(suppressWarnings(library(drake)))
suppressMessages(suppressWarnings(library(magrittr)))
clean(destroy = TRUE, verbose = FALSE)
unlink(c("Makefile", "report.Rmd", "shell.sh", "STDIN.o*", "Thumbs.db"))
knitr::opts_chunk$set(
  collapse = TRUE,
  error = TRUE,
  warning = TRUE
)
```

This vignette is a guide to debugging and testing `drake` projects. Please also see the ["caution" vignette](https://github.com/ropensci/drake/blob/master/vignettes/caution.Rmd), which addresses `drake`'s known edge cases, pitfalls, and weaknesses that may or may not be fixed in future releases. For the most up-to-date information on unhandled edge cases, please visit the [issue tracker](https://github.com/ropensci/drake/issues), where you can submit your own bug reports as well. Be sure to search the closed issues too, especially if you are not using the most up-to-date development version.

# The configuration list

Most of `drake`'s functions rely on a central `config` list. An understanding of `config` will help you grasp the internals. `make()` and `drake_config()` both return the `config` list. Unlike `make()`, `drake_config()`'s return value is visible, and its only purpose is to construct your `config`.

```{r debugconfig}
load_basic_example() # Get the code with drake_example("basic").
config <- drake_config(my_plan)

sort(names(config))
```

The fields of `config` mostly arguments to `make()` and are documented there. The rest of the fields are as follows.

- `graph`: An [igraph](https://github.com/igraph/rigraph) object with the directed acyclic graph (DAG) of the workflow.
- `inventory`: A running list of the cached objects in each `storr` namespace. Maintaining this list helps avoid repeated calls to `config$cache$list()`, which increases speed.
- `long_hash_algo`: Name of the long hash algorithm used throughout `make()`. Used to generate hash keys that *will not* become the names of files. See the [storage vignette](https://github.com/ropensci/drake/blob/master/vignettes/storage.Rmd) for details.
- `seed`: The random number generator seed taken from the user's R session. Each target is built reproducibly using a deterministic function of this seed, and the build does not change the seed outside the scope of the target's command.
- `short_hash_algo`: Name of the short hash algorithm used throughout `make()`. Used to generate hash keys that could become names of files. See the [storage vignette](https://github.com/ropensci/drake/blob/master/vignettes/storage.Rmd) for details.

Early in `make()`, the `config` list is stored in the cache. You can retrieve it with

```{r readconfig, eval = FALSE}
read_drake_config()
```

and you can access parts of it with some companion functions.

```{r readcompanions, eval = FALSE}
read_drake_graph()
read_drake_plan()
```

# Plan your work.

## Workflow plan data frames

The workflow plan data frame is your responsibility, and it takes effort and care. Fortunately, functions in `drake` can help. You can check the plan for formatting issues, missing input files, etc. with the `check_plan()` function.

```{r checkdebug}
load_basic_example() # Get the code with drake_example("basic").
my_plan

check_plan(my_plan) # No issues.
```

## Visualize your workflow.

After quality-checking your plan, you should check that you understand how the steps of your workflow are interconnected. The web of dependencies affects which targets are built and which ones are skipped during `make()`.

```{r demoplotgraphdebug, eval = FALSE}
# Hover, click, drag, zoom, and pan. See args 'from' and 'to'.
config <- drake_config(my_plan)
vis_drake_graph(config, width = "100%", height = "500px")
```

<iframe
src = "https://cdn.rawgit.com/ropensci/drake/e87f05ad/images/outdated.html"
width = "100%" height = "600px" allowtransparency="true"
style="border: none; box-shadow: none">
</iframe>

See the [rendered graph vignette](https://cran.r-project.org/package=drake/vignettes/graph.html) to learn more about how graphing can help (for example, how to visualize small subgraphs). If you want to take control of your own [visNetwork graph](http://datastorm-open.github.io/visNetwork/), use the `dataframes_graph()` function to get data frames of nodes, edges, and legend nodes.


## Check dependency relationships.

Programmatically, several functions can help you check immediate dependencies.

```{r checkdepsdebug}
deps(reg2)

# knitr_in() makes sure your target depends on `report.Rmd`
# and any dependencies loaded with loadd() and readd()
# in the report's active code chunks.
deps(my_plan$command[1])

deps(my_plan$command[nrow(my_plan)])
```

`Drake` takes special precautions so that a target/import does not depend on itself. For example, `deps(f)` might return `"f"` if `f()` is a recursive function, but `make()` just ignores this conflict and runs as expected. In other words, `make()` automatically removes all self-referential loops in the dependency network.

List all the reproducibly-tracked objects and files, including imports and targets.

```{r trackeddebug}
tracked(my_plan, targets = "small")

tracked(my_plan)
```

## Outdated, up to date, and missing items

`missed()` reports import dependencies missing from your environment

```{r misseddebug}
config <- drake_config(my_plan, verbose = FALSE)
missed(config) # Nothing is missing right now.
```

`outdated()` reports any targets that are outdated, plus any downstream targets that depend on them.

```{r outdateddebug}
outdated(config)
```

To find out why a target is out of date, you can load the [storr](https://github.com/richfitz/storr)-based cache and compare the appropriate hash keys to the output of `dependency_profile()`. To use `dependency_profile()`, be sure to supply the master configuration list as the `config` argument. The same is true for `drake_meta()`, another alternative.

```{r depprofiledebug}
load_basic_example() # Get the code with drake_example("basic").
config <- make(my_plan, verbose = FALSE)
# Change a dependency.
reg2 <- function(d) {
  d$x3 <- d$x ^ 3
  lm(y ~ x3, data = d)
}
outdated(config)

dependency_profile(target = "regression2_small", config = config)

drake_meta(target = "regression2_small", config = config)

config$cache$get_hash(key = "small", namespace = "kernels") # same

config$cache$get_hash(key = "small") # same

config$cache$get_hash(key = "reg2", namespace = "kernels") # same

config$cache$get_hash(key = "reg2") # different
```

In `drake`, the "kernel" of a target or import is the piece of the output that is reproducibly tracked. For ordinary R objects, the kernel is just the object itself. For custom external files, it is a separate hash. But for functions, the kernel is the deparsed body of the function, together with the dependency hash if the function is imported (see `drake:::store_function()`).

The internal functions `drake:::meta()` and `drake:::meta_list()` compute the metadata on each target that `drake` uses to decide which targets to build and which to skip (via `drake:::should_build_target()`). Then, after the target/import is processed, `drake:::finish_meta()` updates the metadata (except for the `$missing` element) before it is cached. See `diagnose()` to read available metadata, along with any errors, warnings, and messages generated during the build.

```{r readdrakemeta}
str(diagnose(small))

str(diagnose("\"report.md\""))
```

# Test with triggers.

To track dependencies and make decisions about what needs building, `make()` store the fingerprint, or hash, of each target. Hashing is great for detecting the right changes in targets, but if all you want to do is test and debug a workflow, the full rigor can be time-consuming.

Fortunately, you can change the triggers that tell `drake` when to (re)build each target. Below, `drake` disregards outdatedness and just builds the targets that are missing.

```{r rushdebug}
clean(verbose = FALSE) # Start from scratch
config <- make(my_plan, trigger = "missing")
```

You can choose from any of the following triggers for all targets or for each target individually.

- `always`: Always build the target regardless of the circumstance, even if the target is already up to date. 
- `any`: Apply all the triggers below (default). In other words, trigger a build if the `command` trigger, `depends` trigger, `file` trigger, or `missing` trigger is activated.
- `command`: Build if the workflow plan command changed since the last `make()` or the target is missing.
- `depends`: Build if any of the target's dependencies changed since the last `make()` or if the target is missing.
- `file`: Build if the target is an output file and the file is either missing or corrupted. Also build if the file's hash is missing from the cache.
- `missing`: Build if and only if the target is missing.

To select triggers for individual targets, create an optional `trigger` column in the workflow plan data frame. Entries in this column override the `trigger` argument to `make()`

```{r indivtrigger}
my_plan$trigger <- "command"
my_plan$trigger[1] <- "file"
my_plan

# Change an imported dependency:
reg2

reg2 <- function(d) {
  d$x3 <- d$x ^ 3
  lm(y ~ x3, data = d)
}
make(my_plan, trigger = "any") # Nothing changes!
```

The `outdated()` function responds to triggers. For example, even if `outdated(my_plan)` shows all targets up to date, `outdated(my_plan, trigger = "always")` will claim that all the targets are outdated.

# Skipping imports

Similar to triggers, you can also to skip the processing of imported objects and files. However, *you should only use this for testing purposes*. If some of your imports are not already cached and up to date, any built targets will be out of sync. In other words, `outdated()` is more likely to be wrong, and your project may no longer be reproducible.

```{r skipimports}
clean(verbose = FALSE)
my_plan$trigger <- NULL

make(my_plan, skip_imports = TRUE)
```

# Impose timeouts and retries

See the `timeout`, `cpu`, `elapsed`, and `retries` argument to `make()`.

```{r timeoutretry}
clean(verbose = FALSE)
f <- function(...){
  Sys.sleep(1)
}
debug_plan <- drake_plan(x = 1, y = f(x))
debug_plan

withr::with_message_sink(
  stdout(),
  make(debug_plan, timeout = 1e-3, retries = 2)
)
```

To tailor these settings to each individual target, create new `timeout`, `cpu`, `elapsed`, or `retries` columns in your workflow plan. These columns override the analogous arguments to `make()`.

```{r timeoutretry2}
clean(verbose = FALSE)
debug_plan$timeout <- c(1e-3, 2e-3)
debug_plan$retries <- 1:2

debug_plan

withr::with_message_sink(
  new = stdout(),
  make(debug_plan, timeout = Inf, retries = 0)
)
```

# Diagnose failures.

`Drake` records diagnostic metadata on all your targets, including the latest errors, warnings, messages, and other bits of context.

```{r diagnosedebug}
diagnose(verbose = FALSE) # Targets with available metadata.

f <- function(x){
  if (x < 0){
    stop("`x` cannot be negative.")
  }
  x
}
bad_plan <- drake_plan(
  a = 12,
  b = -a,
  my_target = f(b)
)

bad_plan

withr::with_message_sink(
  new = stdout(),
  make(bad_plan)
)

failed(verbose = FALSE) # from the last make() only

error <- diagnose(my_target, verbose = FALSE)$error # See also warnings and messages.

error$message

error$call

error$calls # View the traceback.
```

To figure out what went wrong, you could try to build the failed target interactively. To do that, simply call `drake_build()`. This function first calls `loadd(deps = TRUE)` to load any missing dependencies (see the `replace` argument here) and then builds your target.

```{r loaddeps}
# Pretend we just opened a new R session.
library(drake)

# Unloads target `b`.
config <- drake_config(plan = bad_plan)

# my_target depends on b.
"b" %in% ls()

# Try to build my_target until the error is fixed.
# Skip all that pesky work checking dependencies.
drake_build(my_target, config = config)

# The target failed, but the dependency was loaded.
"b" %in% ls()

# What was `b` again?
b

# How was `b` used?
diagnose(my_target)$message

diagnose(my_target)$call

f

# Aha! The error was in f(). Let's fix it and try again.
f <- function(x){
  x <- abs(x)
  if (x < 0){
    stop("`x` cannot be negative.")
  }
  x
}

# Now it works!
# Since you called make() previously, `config` is read from the cache
# if you do not supply it.
drake_build(my_target)

readd(my_target)
```

## Tidy evaluation: a caveat to diagnosing interactively

Running commands in your R console is not always exactly like running them with `make()`. That's because `make()` uses tidy evaluation as implemented in the [`rlang` package](https://github.com/tidyverse/rlang).

```{r demotidyeval}
# This workflow plan uses rlang's quasiquotation operator `!!`.
my_plan <- drake_plan(list = c(
  little_b = "\"b\"",
  letter = "!!little_b"
))
my_plan
make(my_plan)
readd(letter)
```


# Debrief a build session.

After your project is at least somewhat built, you can inspect and read your results from the cache.

```{r debriefdebug}
make(my_plan, verbose = FALSE)

# drake_session(verbose = FALSE) # Prints the sessionInfo() of the last make(). # nolint

cached(verbose = FALSE)

built(verbose = FALSE)

imported(verbose = FALSE)

loadd(little_b, verbose = FALSE)

little_b

readd(letter, verbose = FALSE)

progress(verbose = FALSE)

in_progress(verbose = FALSE) # Unfinished targets
```

There are functions to help you locate the project's cache.

```{r finddebug}
find_project()

find_cache()
```

For more information on the cache, see the [storage vignette](https://github.com/ropensci/drake/blob/master/vignettes/storage.Rmd).

# Start tinkering.

The `load_basic_example()` function loads the [basic example](https://github.com/ropensci/drake/tree/master/inst/examples/basic) from `drake_example("basic")` right into your workspace. The workflow plan data frame, workspace, and import files are set up for you. Only `make(my_plan)` is left to you.

`Drake` has [many more built-in examples](https://github.com/ropensci/drake/tree/master/inst/examples). To see your choices, use

```{r examplesdrakedebug}
drake_examples()
```

To write the files for an example, use `drake_example()`.

```{r examplesdrake, eval = FALSE}
drake_example("basic")
drake_example("slurm")
```

```{r rmfiles_debug, echo = FALSE}
clean(destroy = TRUE, verbose = FALSE)
unlink(c("Makefile", "report.Rmd", "shell.sh", "STDIN.o*", "Thumbs.db"))
```
