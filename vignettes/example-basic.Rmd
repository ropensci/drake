---
title: "The basic example"
subtitle: "A thorough walkthrough of drake's main functionality"
author: "William Michael Landau"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette:
    toc: true
    number_sections: true
vignette: >
  %\VignetteIndexEntry{example-basic}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r suppression, echo = F}
suppressMessages(suppressWarnings(library(drake)))
clean(destroy = TRUE, verbose = FALSE)
unlink(c("Makefile", "report.Rmd", "shell.sh", "STDIN.o*", "Thumbs.db"))
knitr::opts_chunk$set(
  collapse = TRUE,
  error = TRUE,
  warning = TRUE
)
```

This vignette is a walkthrough of `drake`'s main functionality based on the basic example. It sets up the project and runs it repeatedly to demonstrate `drake`'s most important functionality.

# Get the code.

Write the code files to your workspace.

```{r getthequickstartcode, eval = FALSE}
drake_example("basic")
```

The new `basic` folder now includes a file structure of a serious `drake` project, plus an `interactive-tutorial.R` to narrate the example. The code is also [online here](https://github.com/ropensci/drake/tree/master/inst/examples/basic).

# Quick examples

Inspect and run your project.

```{r quickstartquickstart, eval = FALSE}
library(drake)
load_basic_example()            # Get the code with drake_example("basic").
config <- drake_config(my_plan) # Master configuration list
vis_drake_graph(config)         # Hover, click, drag, zoom, pan.
make(my_plan)                   # Run the workflow.
outdated(config)                # Everything is up to date.
```

Debug errors.

```{r quickdebug, eval = FALSE}
failed()                   # Targets that failed in the most recent `make()`
context <- diagnose(large) # Diagnostic metadata: errors, warnings, etc.
error <- context$error
str(error)                 # Object of class "error"
error$message
error$call
error$calls                # Full traceback of nested calls leading up to the error. # nolint
```

Dive deeper into the built-in examples.

```{r noeval2, eval = FALSE}
drake_example("basic") # Write the code files.
drake_examples()       # List the other examples.
vignette("quickstart") # This vignette
```

# The motivation of the basic example

Is there an association between the weight and the fuel efficiency of cars? To find out, we use the `mtcars` dataset from the `datasets` package. The `mtcars` dataset originally came from the 1974 Motor Trend US magazine, and it contains design and performance data on 32 models of automobile.

```{r mtcarsquickstart}
# ?mtcars # more info
head(mtcars)
```

Here, `wt` is weight in tons, and `mpg` is fuel efficiency in miles per gallon. We want to figure out if there is an association between `wt` and `mpg`. The `mtcars` dataset itself only has 32 rows, so we generate two larger bootstrapped datasets and then analyze them with regression models. We summarize the regression models to see if there is an association.

# Set up the basic example

Before you run your project, you need to set up the workspace. In other words, you need to gather the "imports": functions, pre-loaded data objects, and saved files that you want to be available before the real work begins.

```{r libs}
library(knitr) # Drake knows which packages you load.
library(drake)
```

We need a function to bootstrap larger datasets from `mtcars`.

```{r sim}
# Pick a random subset of n rows from a dataset
random_rows <- function(data, n){
  data[sample.int(n = nrow(data), size = n, replace = TRUE), ]
}

# Bootstrapped datasets from mtcars.
simulate <- function(n){
  # Pick a random set of cars to bootstrap from the mtcars data.
  data <- random_rows(data = mtcars, n = n)

  # x is the car's weight, and y is the fuel efficiency.
  data.frame(
    x = data$wt,
    y = data$mpg
  )
}
```

We also need functions to apply the regression models we need for detecting associations.

```{r reg}
# Is fuel efficiency linearly related to weight?
reg1 <- function(d){
  lm(y ~ + x, data = d)
}

# Is fuel efficiency related to the SQUARE of the weight?
reg2 <- function(d){
  d$x2 <- d$x ^ 2
  lm(y ~ x2, data = d)
}
```

We want to summarize the final results in an R Markdown report, so we need the following `report.Rmd` source file.

```{r file}
path <- file.path("examples", "basic", "report.Rmd")
report_file <- system.file(path, package = "drake", mustWork = TRUE)
file.copy(from = report_file, to = getwd(), overwrite = TRUE)
```

Here are the contents of the report. It will serve as a final summary of our work, and we will process it at the very end. Admittedly, some of the text spoils the punch line.

```{r readlinesofreport}
cat(readLines("report.Rmd"), sep = "\n")
```

Now, all our imports are set up. When the real work begins, `drake` will import functions and data objects from your R session environment

```{r robjimportsquickstart}
ls()
```

and saved files from your file system.

```{r filesystemimportsquickstart}
list.files()
```

# The workflow plan data frame

Now that your workspace of imports is prepared, we can outline the real work step by step in a workflow plan data frame.

```{r previewmyplan}
load_basic_example() # Get the code with drake_example("basic").
my_plan
```

Each row is an intermediate step, and each **command** generates a single **target**. A target is an output R object (cached when generated) or an output file (specified with single quotes), and a command just an ordinary piece of R code (not necessarily a single function call). Commands make use of R objects imported from your workspace, targets generated by other commands, and initial input files. These dependencies give your project an underlying network representation.

```{r graph1quick, eval = FALSE}
# Hover, click, drag, zoom, and pan.
config <- drake_config(my_plan)
vis_drake_graph(config, width = "100%", height = "500px") # Also drake_graph()
```

<iframe
src = "https://cdn.rawgit.com/ropensci/drake/e87f05ad/images/outdated.html"
width = "100%" height = "600px" allowtransparency="true"
style="border: none; box-shadow: none">
</iframe>

You can also check the dependencies of individual targets and imported functions.

```{r checkdeps}
deps(reg2)

deps(my_plan$command[1]) # Files like report.Rmd are single-quoted.

deps(my_plan$command[nrow(my_plan)])
```

List all the reproducibly-tracked objects and files.

```{r tracked}
tracked(my_plan, targets = "small")

tracked(my_plan)
```

Check for circular reasoning, missing input files, and other pitfalls.

```{r check}
check_plan(my_plan)
```

# Generate the workflow plan

The workflow plan data frame `my_plan` would be a pain to write by hand, so `drake` has functions to help you. Here are the commands to generate the bootstrapped datasets.

```{r datasets}
my_datasets <- drake_plan(
  small = simulate(48),
  large = simulate(64))
my_datasets
```

For multiple replicates:

```{r expand}
expand_plan(my_datasets, values = c("rep1", "rep2"))
```

Here is a template for applying our regression models to our bootstrapped datasets.

```{r methods}
methods <- drake_plan(
  regression1 = reg1(dataset__),
  regression2 = reg2(dataset__))
methods
```

We evaluate the `dataset__` wildcard to generate all the regression commands we need.

```{r analyses}
my_analyses <- plan_analyses(methods, data = my_datasets)
my_analyses
```

Next, we summarize each analysis of each dataset. We calculate descriptive statistics on the residuals, and we collect the regression coefficients and their p-values.

```{r summaries}
summary_types <- drake_plan(
  summ = suppressWarnings(summary(analysis__$residuals)),
  coef = suppressWarnings(summary(analysis__))$coefficients
)
summary_types

results <- plan_summaries(summary_types, analyses = my_analyses,
  datasets = my_datasets, gather = NULL)
results
```

The `gather` feature reduces a collection of targets to a single target. The resulting commands are long, so gathering is deactivated for the sake of readability.

For your `knitr` reports, use `knitr_in()` in your commands so that `report.Rmd` is a dependency and targets loaded with `loadd()` and `readd()` in active code chunks are also dependencies. Use `file_out()` to tell `drake` that the target is a file output. If the file is an output, you do not need to name the target. The target name will be the name of the output file in quotes.

```{r reportplan}
report <- drake_plan(
  knit(knitr_in("report.Rmd"), file_out("report.md"), quiet = TRUE)
)
report
```

Finally, consolidate your workflow using `rbind()`. Row order does not matter.

```{r wholeplan}
my_plan <- rbind(report, my_datasets, my_analyses, results)
my_plan
```

# Flexible workflow plan generation

If your workflow does not fit the rigid datasets/analyses/summaries framework, consider using functions `expand_plan()`, `evaluate_plan()`, and `gather_plan()`.

```{r more_expansions_and_plans}
df <- drake_plan(data = simulate(center = MU, scale = SIGMA))
df

df <- expand_plan(df, values = c("rep1", "rep2"))
df

evaluate_plan(df, wildcard = "MU", values = 1:2)

evaluate_plan(df, wildcard = "MU", values = 1:2, expand = FALSE)

evaluate_plan(df, rules = list(MU = 1:2, SIGMA = c(0.1, 1)), expand = FALSE)

evaluate_plan(df, rules = list(MU = 1:2, SIGMA = c(0.1, 1, 10)))

gather_plan(df)

gather_plan(df, target = "my_summaries", gather = "rbind")
```

# Run the workflow

You may want to check for outdated or missing targets/imports first.

```{r firstmake}
config <- drake_config(my_plan, verbose = FALSE)
outdated(config) # Targets that need to be (re)built.

missed(config) # Checks your workspace.
```

Then just `make(my_plan)`.

```{r firstmakeforreal}
make(my_plan)
```

For the `reg2()` model on the small dataset, the p-value on `x2` is so small that there may be an association between weight and fuel efficiency after all.

```{r getmtcarsanswer}
readd(coef_regression2_small)
```

The non-file dependencies of your last target are already loaded in your workspace.

```{r autoload}
ls()
```

```{r plotgraphfirstmake}
outdated(config) # Everything is up to date.

build_times(digits = 4) # How long did it take to make each target?
```

See also `predict_runtime()` and `rate_limiting_times()`.

In the new graph, the black nodes from before are now green.

```{r graph2quick, eval = FALSE}
# Hover, click, drag, zoom, and pan.
vis_drake_graph(config, width = "100%", height = "500px")
```

<iframe
src = "https://cdn.rawgit.com/ropensci/drake/e87f05ad/images/built.html"
width = "100%" height = "600px" allowtransparency="true"
style="border: none; box-shadow: none">
</iframe>

Optionally, get [visNetwork](http://datastorm-open.github.io/visNetwork/) nodes and edges so you can make your own plot with `visNetwork()` or `render_drake_graph()`.

```{r dfgraph2quick, eval = FALSE}
dataframes_graph(config)
```

Use `readd()` and `loadd()` to load targets into your workspace. (They are cached in the hidden `.drake/` folder using [storr](https://CRAN.R-project.org/package=storr)). There are many more functions for interacting with the cache.

```{r cache}
readd(coef_regression2_large)

loadd(small)

head(small)

rm(small)
cached(small, large)

cached()

built()

imported()

head(read_drake_plan())

head(progress()) # See also in_progress()

progress(large)

# drake_session() # sessionInfo() of the last make() # nolint
```

The next time you run `make(my_plan)`, nothing will build because `drake` knows everything is already up to date.

```{r uptodateinvig}
config <- make(my_plan) # Will use config later. See also drake_config().
```

But if you change one of your functions, commands, or other dependencies, drake will update the affected targets. Suppose we change the quadratic term to a cubic term in `reg2()`. We might want to do this if we suspect a cubic relationship between tons and miles per gallon.

```{r changereg2invignette}
reg2 <- function(d) {
  d$x3 <- d$x ^ 3
  lm(y ~ x3, data = d)
}
```

The targets that depend on `reg2()` need to be rebuilt.

```{r plotwithreg2}
outdated(config)
```

**Advanced**: To find out why a target is out of date, you can load the [storr](https://github.com/richfitz/storr) cache and compare the appropriate hash keys to the output of `dependency_profile()`.

```{r depprofile}
dependency_profile(target = "regression2_small", config = config)

config$cache$get_hash(key = "small") # same

config$cache$get_hash(key = "reg2") # different
```

```{r graph3quick, eval = FALSE}
# Hover, click, drag, zoom, and pan.
# Same as drake_graph():
vis_drake_graph(config, width = "100%", height = "500px")
```

<iframe
src = "https://cdn.rawgit.com/ropensci/drake/e87f05ad/images/reg2.html"
width = "100%" height = "600px" allowtransparency="true"
style="border: none; box-shadow: none">
</iframe>


The next `make()` will rebuild the targets depending on `reg2()` and leave everything else alone.

```{r remakewithreg2}
make(my_plan)
```

Trivial changes to whitespace and comments are totally ignored.

```{r trivial}
reg2 <- function(d) {
  d$x3 <- d$x ^ 3
    lm(y ~ x3, data = d) # I indented here.
}
outdated(config) # Everything is up to date.
```

Drake cares about nested functions too: nontrivial changes to `random_rows()` will propagate to `simulate()`  and all the downstream targets.

```{r, changerandomrows}
random_rows <- function(data, n){
  n <- n + 1
  data[sample.int(n = nrow(data), size = n, replace = TRUE), ]
}

outdated(config)

make(my_plan)
```

Need to add new work on the fly? Just append rows to the workflow plan. If the rest of your workflow is up to date, only the new work is run.

```{r newstuff}
new_simulation <- function(n){
  data.frame(x = rnorm(n), y = rnorm(n))
}

additions <- drake_plan(
  new_data = new_simulation(36) + sqrt(10))
additions

my_plan <- rbind(my_plan, additions)
my_plan

make(my_plan)
```

If you ever need to erase your work, use `clean()`. The next `make()` will rebuild any cleaned targets, so be careful. You may notice that by default, the size of the cache does not go down very much. To purge old data, you could use `clean(garbage_collection = TRUE, purge = TRUE)`. To do garbage collection without removing any important targets, use `drake_gc()`.

```{r cleanup}
# Uncaches individual targets and imported objects.
clean(small, reg1, verbose = FALSE)
clean(verbose = FALSE) # Cleans all targets out of the cache.
drake_gc(verbose = FALSE) # Just garbage collection.
clean(destroy = TRUE, verbose = FALSE) # removes the cache entirely
```

# Automatic watching for changed dependencies

As you have seen with `reg2()`, `drake` reacts to changes in dependencies. In other words, `make()` notices when your dependencies are different from last time, rebuilds any affected targets, and continues downstream. In particular, `drake` watches for nontrivial changes to the following items as long as they are connected to your workflow.

1. The output values of targets in your workflow plan.
1. The commands themselves.
1. External files, if their names are enclosed in single quotes in commands.
1. R objects mentioned in the commands, including but not limited to user-defined functions and functions from packages.
1. R objects (but not files) nested inside user-defined functions.
1. For packages exposed with `expose_imports()`, R objects (but not files) nested inside package functions.
1. Files declared with `file_in()` inside your commands or custom functions.
1. `knitr` reports declared with `knitr_in()` in your commands, along with any targets explicitly loaded in active code chunks with `loadd()` or `readd()`. Do not use `knitr_in()` inside your imported functions.
1. Files declared with `file_out()` in your commands. Do not use `file_out()` inside your imported functions.

To enhance reproducibility beyond the scope of drake, you might consider [packrat](https://rstudio.github.io/packrat) and a container tool (such as [Singularity](http://singularity.lbl.gov/) or [Docker](https://www.docker.com/). [Packrat](https://rstudio.github.io/packrat) creates a tightly-controlled local library of packages to extend the shelf life of your project. And with containerization, you can execute your project on a [virtual machine](https://en.wikipedia.org/wiki/Virtual_machine) to ensure platform independence. Together, [packrat](https://rstudio.github.io/packrat) and containers can help others reproduce your work even if they have different software and hardware.

# A note on tidy evaluation

Running commands in your R console is not always exactly like running them with `make()`. That's because `make()` uses tidy evaluation as implemented in the [`rlang` package](https://github.com/tidyverse/rlang).

```{r demotidyeval}
# This workflow plan uses rlang's quasiquotation operator `!!`.
my_plan <- drake_plan(list = c(
  little_b = "\"b\"",
  letter = "!!little_b"
))
my_plan
make(my_plan)
readd(letter)
```

For the commands you specify the free-form `...` argument, `drake_plan()` also supports tidy evaluation. For example, it supports quasiquotation with the `!!` argument. Use `tidy_evaluation = FALSE` or the `list` argument to suppress this behavior.

```{r testquasiquoplan}
my_variable <- 5

drake_plan(
  a = !!my_variable,
  b = !!my_variable + 1,
  list = c(d = "!!my_variable")
)

drake_plan(
  a = !!my_variable,
  b = !!my_variable + 1,
  list = c(d = "!!my_variable"),
  tidy_evaluation = FALSE
)
```

For instances of `!!` that remain in the workflow plan, `make()` will run these commands in tidy fashion, evaluating the `!!` operator using the environment you provided.

# Need more speed?

`Drake` has extensive high-performance computing support, from local multicore processing to serious distributed computing across multiple nodes of a cluster. See the [parallelism vignette](https://github.com/ropensci/drake/blob/master/vignettes/parallelism.Rmd) for detailed instructions.

```{r endofline_quickstart, echo = F}
clean(destroy = TRUE, verbose = FALSE)
unlink(c("Makefile", "report.Rmd", "shell.sh", "STDIN.o*", "Thumbs.db"))
```
